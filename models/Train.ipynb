{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./files/test_32x32.mat\n",
      "torch.Size([26032, 3, 32, 32])\n",
      "(26032,)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "torch.manual_seed(5531)\n",
    "\n",
    "# Prepare trainig data\n",
    "train_data = torchvision.datasets.SVHN('./files/', \n",
    "                                  split='test', #Tak.\n",
    "                                  download=True)\n",
    "\n",
    "train_X = (torch.tensor(train_data.data)/255).to(torch.float)\n",
    "train_y = train_data.labels\n",
    "\n",
    "dataset = TensorDataset(torch.Tensor(train_X),torch.Tensor(train_y))\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.1914854\n",
      "0 51 0.7555662\n",
      "0 101 0.78944904\n",
      "0 151 0.8039864\n",
      "0 201 0.81441087\n",
      "0 251 0.82296103\n",
      "0 301 0.8299477\n",
      "0 351 0.8350868\n",
      "0 401 0.83927864\n",
      "0 451 0.8424678\n",
      "0 501 0.8451011\n",
      "0 551 0.8473635\n",
      "0 601 0.8492799\n",
      "0 651 0.85096747\n",
      "0 701 0.8524579\n",
      "1 1 0.18801624\n",
      "1 51 0.8362857\n",
      "1 101 0.85830474\n",
      "1 151 0.8693057\n",
      "1 201 0.8749631\n",
      "1 251 0.8786195\n",
      "1 301 0.88175875\n",
      "1 351 0.8840639\n",
      "1 401 0.88642263\n",
      "1 451 0.8885215\n",
      "1 501 0.89071083\n",
      "1 551 0.8924491\n",
      "1 601 0.8932621\n",
      "1 651 0.8945484\n",
      "1 701 0.8959729\n",
      "2 1 0.18699118\n",
      "2 51 0.85794234\n",
      "2 101 0.87988263\n",
      "2 151 0.8895973\n",
      "2 201 0.89564013\n",
      "2 249 0.90001243\n",
      "3 1 0.18811534\n",
      "3 51 0.87535757\n",
      "3 95 0.900252\n",
      "4 1 0.18955737\n",
      "4 51 0.890464\n",
      "4 64 0.90029675\n"
     ]
    }
   ],
   "source": [
    "from methods.architectures import *\n",
    "\n",
    "# Initialize and train classifiers\n",
    "max_training_epochs = 750\n",
    "training_support_level = 0.9\n",
    "\n",
    "clfs = [\n",
    "    CNN(architecure=CNN1_5_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN2_5_10_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN2_10_15_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN2_20_30_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN2_25_40_Network(img_depth=3, x_input_size=32)),\n",
    "]\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for clf_id, clf in enumerate(clfs):\n",
    "    optimizer = torch.optim.SGD(clf.parameters(), lr=1e-2)\n",
    "\n",
    "    for e in range(max_training_epochs):\n",
    "        if e==0:\n",
    "            clf.custom_train(dataloader, loss_fn, optimizer)\n",
    "        else:\n",
    "\n",
    "            proba = nn.Softmax(dim=1)(clf(train_X))\n",
    "            max_proba = torch.max(proba, dim=1)[0] \n",
    "            mean_proba = torch.mean(max_proba).detach().numpy() # Å›rednie wsparcie decyzyjne\n",
    "\n",
    "            if mean_proba>training_support_level:\n",
    "                print(clf_id, e, mean_proba)\n",
    "                break\n",
    "            \n",
    "            clf.custom_train(dataloader, loss_fn, optimizer)\n",
    "        \n",
    "        if e%50==1:\n",
    "            print(clf_id, e, mean_proba)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8822218807621389 0.8646008968353271\n",
      "1 0.9147587584511371 0.7050721645355225\n",
      "2 0.9153733866011063 1.3436081409454346\n",
      "3 0.9169099569760295 3.3284401893615723\n",
      "4 0.9228257529194838 4.940171957015991\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import time \n",
    "\n",
    "# Test on training data\n",
    "for c_id, c in enumerate(clfs):\n",
    "    st = time.time()\n",
    "    proba = nn.Softmax(dim=1)(c(train_X))\n",
    "    p = torch.argmax(proba, dim=1)    \n",
    "    el = time.time() - st\n",
    "    \n",
    "    print(c_id, accuracy_score(train_y, p), el)\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
