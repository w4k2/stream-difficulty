{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EKSPERYMENT 1\n",
    "### Komputer.\n",
    "\n",
    "Część 1: Przygotowanie danych i trenowanie klasyfikatorów\n",
    "\n",
    "Część 2: Generacja strumieni i set-up\n",
    "\n",
    "Część 3: Badanie jakości w strumieniu o zmiennej strudności"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 1: Trenowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./files/test_32x32.mat\n",
      "torch.Size([26032, 3, 32, 32])\n",
      "(26032,)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Prepare trainig data\n",
    "train_data = torchvision.datasets.SVHN('./files/', \n",
    "                                  split='test', #Tak.\n",
    "                                  download=True)\n",
    "\n",
    "train_X = (torch.tensor(train_data.data)/255).to(torch.float)\n",
    "train_y = train_data.labels\n",
    "\n",
    "dataset = TensorDataset(torch.Tensor(train_X),torch.Tensor(train_y))\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.18599488\n",
      "0 51 0.75039804\n",
      "0 71 0.80021524\n",
      "1 1 0.19139028\n",
      "1 51 0.7952793\n",
      "1 58 0.8006154\n",
      "2 1 0.19166751\n",
      "2 51 0.7975261\n",
      "2 53 0.800293\n",
      "3 1 0.18786322\n",
      "3 36 0.8010007\n",
      "4 1 0.18638173\n",
      "4 16 0.80085456\n",
      "5 1 0.18681403\n",
      "5 45 0.8028484\n"
     ]
    }
   ],
   "source": [
    "from architectures import CNN, CNN1_10_Network, CNN1_5_Network, CNN2_10_20_Network, CNN2_5_10_Network, CNN3_5_10_20_Network, FC_Network\n",
    "\n",
    "# Initialize and train classifiers\n",
    "max_training_epochs = 250\n",
    "training_support_level = 0.8\n",
    "\n",
    "clfs = [\n",
    "    CNN(architecure=FC_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN1_5_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN1_10_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN2_5_10_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN2_10_20_Network(img_depth=3, x_input_size=32)),\n",
    "    CNN(architecure=CNN3_5_10_20_Network(img_depth=3, x_input_size=32)),  \n",
    "]\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for clf_id, clf in enumerate(clfs):\n",
    "    optimizer = torch.optim.SGD(clf.parameters(), lr=1e-2)\n",
    "\n",
    "    for e in range(max_training_epochs):\n",
    "        if e==0:\n",
    "            clf.train(dataloader, loss_fn, optimizer)\n",
    "        else:\n",
    "\n",
    "            proba = nn.Softmax(dim=1)( clf(train_X))\n",
    "            max_proba = torch.max(proba, dim=1)[0] \n",
    "            mean_proba = torch.mean(max_proba).detach().numpy() # średnie wsparcie decyzyjne\n",
    "\n",
    "            if mean_proba>training_support_level:\n",
    "                print(clf_id, e, mean_proba)\n",
    "                break\n",
    "            \n",
    "            clf.train(dataloader, loss_fn, optimizer)\n",
    "        \n",
    "        if e%50==1:\n",
    "            print(clf_id, e, mean_proba)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classifers\n",
    "for c_id, c in enumerate(clfs):\n",
    "    torch.save(c, 'models/%i.pt' % c_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 2: Przygotowanie strumieni i CDoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./files/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from ConditionalEvidenceStream import ConditionalEvidenceStream\n",
    "from utils import make_condition_map, mix_to_factor\n",
    "import concepts\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Load data\n",
    "stream_data = torchvision.datasets.SVHN('./files/', \n",
    "                                  split='train', \n",
    "                                  download=True)\n",
    "\n",
    "X = torch.tensor(stream_data.data)/255\n",
    "y = stream_data.labels\n",
    "\n",
    "X_pca = PCA(n_components=0.8).fit_transform(X.reshape(X.shape[0],-1))\n",
    "X_pca -= np.mean(X_pca, axis=0)\n",
    "X_pca /= np.std(X_pca, axis=0)\n",
    "\n",
    "factor = mix_to_factor(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joana/Documents/projects/stream-difficulty/concepts.py:50: RuntimeWarning: invalid value encountered in divide\n",
      "  concept_proba = concept_proba / np.sum(concept_proba, axis=1)[:,None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 25) (1000, 25, 3, 32, 32)\n",
      "(1000, 250) (1000, 250, 3, 32, 32)\n",
      "(1000, 250) (1000, 250, 3, 32, 32)\n",
      "(1000, 250) (1000, 250, 3, 32, 32)\n",
      "(1000, 250) (1000, 250, 3, 32, 32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m     stream_y[chunk_id] \u001b[39m=\u001b[39m _y\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(stream_y\u001b[39m.\u001b[39mshape, stream_X\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 41\u001b[0m np\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39;49m\u001b[39mstreams/X_cs\u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39m_nc\u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39m_m_\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m.npy\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m (cs, nc, mode), stream_X)\n\u001b[1;32m     42\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mstreams/y_cs\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m_nc\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m_m_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (cs, nc, mode), stream_y)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/numpy/lib/npyio.py:522\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mwith\u001b[39;00m file_ctx \u001b[39mas\u001b[39;00m fid:\n\u001b[1;32m    521\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 522\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_array(fid, arr, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    523\u001b[0m                        pickle_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(fix_imports\u001b[39m=\u001b[39;49mfix_imports))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/numpy/lib/format.py:722\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 722\u001b[0m         array\u001b[39m.\u001b[39;49mtofile(fp)\n\u001b[1;32m    723\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m numpy\u001b[39m.\u001b[39mnditer(\n\u001b[1;32m    725\u001b[0m                 array, flags\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mexternal_loop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbuffered\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mzerosize_ok\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    726\u001b[0m                 buffersize\u001b[39m=\u001b[39mbuffersize, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Experimental setup\n",
    "n_chunks = 1000\n",
    "chunk_size = [25, 250, 500]\n",
    "n_cycles = [5, 10, 25]\n",
    "modes = {\n",
    "    'instant': {'mode': 'instant'},\n",
    "    'normal_1': {'mode': 'normal', 'sigma': 1},\n",
    "    'normal_3': {'mode': 'normal', 'sigma': 3}\n",
    "    }\n",
    "\n",
    "for cs_id, cs in enumerate(chunk_size):\n",
    "    for n_c_id, nc in enumerate(n_cycles):\n",
    "        for m_id, mode in enumerate(modes):\n",
    "\n",
    "            condition_map = make_condition_map(n_cycles=nc,\n",
    "                                            n_concepts=500,\n",
    "                                            factor=factor,\n",
    "                                            factor_range=(0.1,0.9))\n",
    "\n",
    "            cp = concepts.concept_proba(n_concepts=500,\n",
    "                                        n_chunks=n_chunks,\n",
    "                                        normalize=True,\n",
    "                                        **modes[mode])\n",
    "\n",
    "            stream = ConditionalEvidenceStream(X, y,\n",
    "                                            condition_map.T,\n",
    "                                            cp,\n",
    "                                            chunk_size=cs,\n",
    "                                            fragile=False)\n",
    "            \n",
    "            \n",
    "            # Nie da się tego przechować.\n",
    "            # stream_X = np.zeros((n_chunks, cs, 3, 32, 32))\n",
    "            # stream_y = np.zeros((n_chunks, cs))\n",
    "            \n",
    "            # for chunk_id in range(n_chunks):\n",
    "            #     _X, _y = stream.get_chunk()\n",
    "            #     stream_X[chunk_id] = _X\n",
    "            #     stream_y[chunk_id] = _y\n",
    "            \n",
    "            # print(stream_y.shape, stream_X.shape)\n",
    "            # np.save('streams/X_cs%i_nc%i_m_%s.npy' % (cs, nc, mode), stream_X)\n",
    "            # np.save('streams/y_cs%i_nc%i_m_%s.npy' % (cs, nc, mode), stream_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
